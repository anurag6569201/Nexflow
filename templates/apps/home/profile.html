{% extends "allauth/layouts/main_base.html" %}
{% load i18n %}
{% load static %}
{% load allauth account %}
{% block head_title %}
{% trans "Profile" %}
{% endblock head_title %}
{% block stylesheet %}
<link rel="stylesheet" href="{% static 'assets/css/home/profile.css' %}">
{% endblock stylesheet %}
{% block pages %}

<div class="row">
    <div class="col-md-12">
        <h1 class="audio_heading">Audio Recorder</h1>
    </div>
    <div class="col-md-12 app">
        <div class="row" style="position: relative;">
            <div class="col-md-6">
                <select name="" id="micSelect"></select>
            </div>
            <div class="col-md-6">
                <select id="visSelect">
                    <option value="frequencybars">Bar</option>
                    <option value="sinewave">Wave</option>
                    <option value="circle">Circle</option>
                </select>
            </div>
            <div class="col-md-12 mt-4" style="display: flex;align-items: center;justify-content: center;">
                <canvas class="frquency_canvas"></canvas>
            </div>
            <div class="col-md-12">
                <div class="audio-controls">
                    <button id="record" class="btn-12"><span>Record</span></button>
                    <button id="stop" class="btn-12"><span>Stop</span></button>
                    <audio id="audio" controls></audio>
                    <a id="download" class="btn-12" style="mix-blend-mode:exclusion;"><span>Download</span></a>
                    <button id="auto_record" class="btn-12"><span>Start Auto Record</span></button>
                </div>
            </div>
            <div class="col-md-12">
                <div id="msg">Recording...</div>
                <p id="status"></p>
            </div>
        </div>

    </div>
</div>


<script>
    (async () => {
        let leftchannel = [];
        let rightchannel = [];
        let recorder = null;
        let recording = false;
        let recordingLength = 0;
        let volume = null;
        let audioInput = null;
        let sampleRate = null;
        let AudioContext = window.AudioContext || window.webkitAudioContext;
        let context = null;
        let analyser = null;
        let canvas = document.querySelector('canvas');
        let canvasCtx = canvas.getContext("2d");
        let visualSelect = document.querySelector('#visSelect');
        let micSelect = document.querySelector('#micSelect');
        let stream = null;
        let tested = false;

        try {
            window.stream = stream = await getStream();
            console.log('Got stream');
        } catch (err) {
            alert('Issue getting mic', err);
        }

        const deviceInfos = await navigator.mediaDevices.enumerateDevices();

        var mics = [];
        for (let i = 0; i !== deviceInfos.length; ++i) {
            let deviceInfo = deviceInfos[i];
            if (deviceInfo.kind === 'audioinput') {
                mics.push(deviceInfo);
                let label = deviceInfo.label ||
                    'Microphone ' + mics.length;
                console.log('Mic ', label + ' ' + deviceInfo.deviceId)
                const option = document.createElement('option')
                option.value = deviceInfo.deviceId;
                option.text = label;
                micSelect.appendChild(option);
            }
        }

        function getStream(constraints) {
            if (!constraints) {
                constraints = { audio: true, video: false };
            }
            return navigator.mediaDevices.getUserMedia(constraints);
        }


        setUpRecording();

        function setUpRecording() {
            context = new AudioContext();
            sampleRate = context.sampleRate;

            // creates a gain node
            volume = context.createGain();

            // creates an audio node from teh microphone incoming stream
            audioInput = context.createMediaStreamSource(stream);

            // Create analyser
            analyser = context.createAnalyser();

            // connect audio input to the analyser
            audioInput.connect(analyser);

            // connect analyser to the volume control
            // analyser.connect(volume);

            let bufferSize = 2048;
            let recorder = context.createScriptProcessor(bufferSize, 2, 2);

            // we connect the volume control to the processor
            // volume.connect(recorder);

            analyser.connect(recorder);

            // finally connect the processor to the output
            recorder.connect(context.destination);

            recorder.onaudioprocess = function (e) {
                // Check 
                if (!recording) return;
                // Do something with the data, i.e Convert this to WAV
                console.log('recording');
                let left = e.inputBuffer.getChannelData(0);
                let right = e.inputBuffer.getChannelData(1);
                if (!tested) {
                    tested = true;
                    // if this reduces to 0 we are not getting any sound
                    if (!left.reduce((a, b) => a + b)) {
                        alert("There seems to be an issue with your Mic");
                        // clean up;
                        stop();
                        stream.getTracks().forEach(function (track) {
                            track.stop();
                        });
                        context.close();
                    }
                }
                // we clone the samples
                leftchannel.push(new Float32Array(left));
                rightchannel.push(new Float32Array(right));
                recordingLength += bufferSize;
            };
            visualize();
        };



        function mergeBuffers(channelBuffer, recordingLength) {
            let result = new Float32Array(recordingLength);
            let offset = 0;
            let lng = channelBuffer.length;
            for (let i = 0; i < lng; i++) {
                let buffer = channelBuffer[i];
                result.set(buffer, offset);
                offset += buffer.length;
            }
            return result;
        }

        function interleave(leftChannel, rightChannel) {
            let length = leftChannel.length + rightChannel.length;
            let result = new Float32Array(length);

            let inputIndex = 0;

            for (let index = 0; index < length;) {
                result[index++] = leftChannel[inputIndex];
                result[index++] = rightChannel[inputIndex];
                inputIndex++;
            }
            return result;
        }

        function writeUTFBytes(view, offset, string) {
            let lng = string.length;
            for (let i = 0; i < lng; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function start() {
            recording = true;
            document.querySelector('#msg').style.visibility = 'visible'
            // reset the buffers for the new recording
            leftchannel.length = rightchannel.length = 0;
            recordingLength = 0;
            console.log('context: ', !!context);
            if (!context) setUpRecording();
        }

        function stop() {
            console.log('Stop')
            recording = false;
            document.querySelector('#msg').style.visibility = 'hidden'


            // we flat the left and right channels down
            let leftBuffer = mergeBuffers(leftchannel, recordingLength);
            let rightBuffer = mergeBuffers(rightchannel, recordingLength);
            // we interleave both channels together
            let interleaved = interleave(leftBuffer, rightBuffer);

            ///////////// WAV Encode /////////////////
            // from http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/
            //

            // we create our wav file
            let buffer = new ArrayBuffer(44 + interleaved.length * 2);
            let view = new DataView(buffer);

            // RIFF chunk descriptor
            writeUTFBytes(view, 0, 'RIFF');
            view.setUint32(4, 44 + interleaved.length * 2, true);
            writeUTFBytes(view, 8, 'WAVE');
            // FMT sub-chunk
            writeUTFBytes(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            // stereo (2 channels)
            view.setUint16(22, 2, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 4, true);
            view.setUint16(32, 4, true);
            view.setUint16(34, 16, true);
            // data sub-chunk
            writeUTFBytes(view, 36, 'data');
            view.setUint32(40, interleaved.length * 2, true);

            // write the PCM samples
            let lng = interleaved.length;
            let index = 44;
            let volume = 1;
            for (let i = 0; i < lng; i++) {
                view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
                index += 2;
            }

            // our final binary blob
            const blob = new Blob([view], { type: 'audio/wav' });
            saveAudioToServer(blob);

            const audioUrl = URL.createObjectURL(blob);
            console.log('BLOB ', blob);
            console.log('URL ', audioUrl);
            document.querySelector('#audio').setAttribute('src', audioUrl);
            const link = document.querySelector('#download');
            link.setAttribute('href', audioUrl);
            link.download = 'output.wav';
        }

        // Visualizer function from
        // https://webaudiodemos.appspot.com/AudioRecorder/index.html
        //
        function visualize() {
            WIDTH = canvas.width;
            HEIGHT = canvas.height;
            CENTERX = canvas.width / 2;
            CENTERY = canvas.height / 2;

            let visualSetting = visualSelect.value;
            console.log(visualSetting);
            if (!analyser) return;

            if (visualSetting === "sinewave") {
                analyser.fftSize = 2048;
                var bufferLength = analyser.fftSize;
                console.log(bufferLength);
                var dataArray = new Uint8Array(bufferLength);

                canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

                var draw = function () {

                    drawVisual = requestAnimationFrame(draw);

                    analyser.getByteTimeDomainData(dataArray);

                    canvasCtx.fillStyle = '#0e7c66';
                    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                    canvasCtx.lineWidth = 2;
                    canvasCtx.strokeStyle = 'rgb(50, 200, 150';

                    canvasCtx.beginPath();

                    var sliceWidth = WIDTH * 1.0 / bufferLength;
                    var x = 0;

                    for (var i = 0; i < bufferLength; i++) {

                        var v = dataArray[i] / 128.0;
                        var y = v * HEIGHT / 2;

                        if (i === 0) {
                            canvasCtx.moveTo(x, y);
                        } else {
                            canvasCtx.lineTo(x, y);
                        }

                        x += sliceWidth;
                    }

                    canvasCtx.lineTo(canvas.width, canvas.height / 2);
                    canvasCtx.stroke();
                };

                draw();

            } else if (visualSetting == "frequencybars") {
                analyser.fftSize = 256;
                var bufferLengthAlt = analyser.frequencyBinCount;
                console.log(bufferLengthAlt);
                var dataArrayAlt = new Uint8Array(bufferLengthAlt);

                canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

                var drawAlt = function () {
                    drawVisual = requestAnimationFrame(drawAlt);

                    analyser.getByteFrequencyData(dataArrayAlt);

                    canvasCtx.fillStyle = '#0e7c66'; // Darker background
                    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                    var barWidth = (WIDTH / bufferLengthAlt) * 0.8; // Reduce bar width for narrower bars
                    var barHeight;
                    var x = 0;

                    for (var i = 0; i < bufferLengthAlt; i++) {
                        barHeight = dataArrayAlt[i];

                        // Create a gradient for better visuals
                        var gradient = canvasCtx.createLinearGradient(x, HEIGHT, x, HEIGHT - barHeight / 2);
                        gradient.addColorStop(0, 'rgb(24, ' + (barHeight + 90) + ', 102)');
                        gradient.addColorStop(1, 'rgb(50, 200, 150)');

                        canvasCtx.fillStyle = gradient;
                        canvasCtx.fillRect(x, HEIGHT - barHeight / 2, barWidth, barHeight / 2);

                        x += barWidth + 2; // Increase spacing between bars
                    }
                };

                drawAlt();
            } else if (visualSetting == "circle") {
                analyser.fftSize = 256;
                let bufferLength = analyser.frequencyBinCount;
                console.log(bufferLength);
                let dataArray = new Uint8Array(bufferLength);

                canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

                let draw = () => {
                    drawVisual = requestAnimationFrame(draw);

                    analyser.getByteFrequencyData(dataArray);

                    // Clear the canvas
                    canvasCtx.fillStyle = '#0e7c66'; // Slight transparency for a smooth fading effect
                    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                    // Calculate dynamic radius based on frequency data
                    let averageFrequency = dataArray.reduce((a, b) => a + b) / bufferLength;
                    let radius = averageFrequency / 2;
                    if (radius < 20) radius = 20;
                    if (radius > 150) radius = 150;

                    // Create gradient for the stroke
                    let gradient = canvasCtx.createRadialGradient(CENTERX, CENTERY, radius - 20, CENTERX, CENTERY, radius + 20);
                    gradient.addColorStop(0, 'rgb(50, 50, ' + (radius + 100) + ')');
                    gradient.addColorStop(1, 'rgb(200, 100, ' + (radius + 150) + ')');

                    // Draw the main circle
                    canvasCtx.beginPath();
                    canvasCtx.arc(CENTERX, CENTERY, radius, 0, 2 * Math.PI, false);
                    canvasCtx.lineWidth = 6;
                    canvasCtx.strokeStyle = gradient;
                    canvasCtx.stroke();

                    // Add an inner pulse effect
                    canvasCtx.beginPath();
                    canvasCtx.arc(CENTERX, CENTERY, radius - 10, 0, 2 * Math.PI, false);
                    canvasCtx.lineWidth = 3;
                    canvasCtx.strokeStyle = 'rgba(255, 255, 255, 0.5)'; // Soft white glow
                    canvasCtx.stroke();

                    // Add frequency bars radiating outwards
                    let angleStep = (2 * Math.PI) / bufferLength;
                    for (let i = 0; i < bufferLength; i++) {
                        let value = dataArray[i] / 2;
                        let angle = i * angleStep;

                        let x1 = CENTERX + Math.cos(angle) * (radius + 10);
                        let y1 = CENTERY + Math.sin(angle) * (radius + 10);
                        let x2 = CENTERX + Math.cos(angle) * (radius + 10 + value);
                        let y2 = CENTERY + Math.sin(angle) * (radius + 10 + value);

                        canvasCtx.beginPath();
                        canvasCtx.moveTo(x1, y1);
                        canvasCtx.lineTo(x2, y2);
                        canvasCtx.lineWidth = 2;
                        canvasCtx.strokeStyle = 'rgb(' + (value + 100) + ', 100, 255)';
                        canvasCtx.stroke();
                    }
                };

                draw();
            }


        }

        visualSelect.onchange = function () {
            window.cancelAnimationFrame(drawVisual);
            visualize();
        };

        micSelect.onchange = async e => {
            console.log('now use device ', micSelect.value);
            stream.getTracks().forEach(function (track) {
                track.stop();
            });
            context.close();

            stream = await getStream({
                audio: {
                    deviceId: { exact: micSelect.value }
                }, video: false
            });
            setUpRecording();
        }

        function pause() {
            recording = false;
            context.suspend()
        }

        function resume() {
            recording = true;
            context.resume();
        }

        document.querySelector('#record').onclick = (e) => {
            console.log('Start recording')
            start();
        }

        document.querySelector('#stop').onclick = (e) => {
            stop();
        }

        let loopCounter = 0;
        const maxLoops = 3;
        const recordDuration = 30000;
        let recordingInterval;

        function auto_running() {
            if (loopCounter < maxLoops) {
                start(); // Start recording
                setTimeout(() => {
                    stop(); // Stop recording after 1 minute
                    loopCounter++; // Increment loop counter
                    auto_running(); // Call the function recursively for the next loop
                }, recordDuration);
            } else {
                console.log("Completed all recording loops.");
                document.getElementById("msg").innerText = "Completed all recordings.";
                clearInterval(recordingInterval);
            }
        }
        document.getElementById("auto_record").addEventListener("click", () => {
            loopCounter = 0; // Reset loop counter
            auto_running();
        });
    })()

    function saveAudioToServer(audioBlob) {
        const formData = new FormData();
        formData.append('audio_file', audioBlob, 'audio.wav');

        fetch('save/audio/', {
            method: 'POST',
            body: formData
        })
        .then(response => response.json())
        .then(data => {
            console.log('Audio saved successfully:', data);
            document.getElementById('status').innerText = "Audio saved successfully!";
        })
        .catch(error => {
            console.error('Error saving audio:', error);
            document.getElementById('status').innerText = "Error saving audio.";
        });
    }
</script>

{% endblock pages %}